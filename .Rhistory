test1 <- predict(model1, testPC)
confusionMatrix(testing$diagnosis, test1)
preProcess(training[il_idx], method="pca", thresh=0.8)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(training)
hist(training$Superplasticizer)
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer) - 1)
hist(log10(training$Superplasticizer))
hist(log10(training$Superplasticizer) + 1)
hist(log10(training$Superplasticizer) + 2)
hist(log10(training$Superplasticizer) + 3)
hist(log10(training$Superplasticizer) + 4)
qplot(Superplasticizer, data=training, geom="histogram")
table(training$Superplasticizer)
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
hist(log10(training$Superplasticizer+1))
library(swirl)
swirl()
install.packages("ISLR")
data(Wage)
data(wage)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
filename <- basename(url)
if(!file.exists(filename))
{
download.file(url, filename, mode = "wb")
}
train <- read.csv(filename)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename <- basename(url)
if(!file.exists(filename))
{
download.file(url, filename, mode = "wb")
}
test <- read.csv(filename)
sort(names(train))
isAnyMissing <- sapply(test, function (x) any(is.na(x) | x == ""))
isAnyMissing
isAnyMissing[FALSE]
names(isAnyMissing)
names(isAnyMissing)[isAnyMissing]
names(isAnyMissing)[!isAnyMissing]
train[,classe]
train[,!isAnyMissing]
View(train)
names(train)[names(train) == "classe"]
nrow(names(train)[names(train) == "classe"])
sum(names(train)[names(train) == "classe"])
names(train)
train[,157:160]
train[3000:3050,157:160]
isNa <- sapply(test, function(x) any(is.na(x)) | x = "")
isNa <- sapply(test, function (x) any(is.na(x) | x == ""))
isPredictor <- !isNa & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(isAnyMissing))
head(isPredictor)
head(!isNa)
predictorCol <- names(isAnyMissing)[isPredictor]
names(train[,c(predictorCol, 160)])
names(train[,predictorCol])
outcomeCol <- grep("^classe$", names(train))
outcomeCol
names(train[,c(outcomeCol, predictorCol)])
head(train[,c(outcomeCol, predictorCol)])
allCol <- c(outcomeCol, predictorCol)
names(train[,allCol])
allCol
outcomeCol <- grepl("^classe$", names(train))
outcomeCol
names(train[,c("classe", predictorCol)])
test <- test[, c("classe", predictorCol)]
train <- train[, c("classe", predictorCol)]
names(test)
sort(names(test))
test <- test[, c(predictorCol)]
train <- read.csv(filename)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename <- basename(url)
if(!file.exists(filename))
{
download.file(url, filename, mode = "wb")
}
test <- read.csv(filename)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
filename <- basename(url)
if(!file.exists(filename))
{
download.file(url, filename, mode = "wb")
}
train <- read.csv(filename)
url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
filename <- basename(url)
if(!file.exists(filename))
{
download.file(url, filename, mode = "wb")
}
test <- read.csv(filename)
isNa <- sapply(test, function (x) any(is.na(x) | x == ""))
isPredictor <- !isNa & grepl("belt|[^(fore)]arm|dumbbell|forearm", names(isNa))
predictorCol <- names(isNa)[isPredictor]
test <- test[, c("problem_id", predictorCol)] # problem_id is the test case key
train <- train[, c("classe", predictorCol)] # classe is the outcome column
names(train)
trainFact <- as.factor(train$classe)
str(trainFact)
summary(trainFact)
train$classe <- as.factor(train$classe)
summary(train$classe)
library(caret)
suppress.Warning(library(caret))
suppressWarning(library(caret))
suppressWarnings(library(caret))
set.seed(1722)
inTrain <- createDataPartition(train$classe, p = 0.6, list = F)[[1]]
inTrain
inTrain <- createDataPartition(train$classe, p = 0.6, list = F)
inTrain
inTrain <- createDataPartition(train$classe, p = 0.6)[[1]]
trainData <- train[inTrain, ]
testData <- train[inTrain, ]
testData <- train[-inTrain, ]
7846/(11776 + 7836)
7846/(11776 + 7846)
trainDataPreproc <- preProcess(testData[, predictorCol])
trainDataPreproc
trainDataPreproc <- preProcess(trainData[, predictorCol])
trainDataPreproc
?predict
trainDataPredict <- predict(trainDataPreproc, trainData[, predictorCol])
trainDataCS <- c(classe, trainDataPredict)
trainDataCS <- c(trainData$classe, trainDataPredict)
trainDataCS <- cbind(trainData$classe, trainDataPredict)
nzv <- nearZeroVar(trainDataCS, saveMetrics = TRUE)
head(nzv)
testDataPreproc <- preProcess(testData[, predictorCol])
testDataPredict <- predict(testDataPreproc, testData[, predictorCol])
testDataCS <- cbind(testData$classe, testDataPredict)
names(trainDataCS)$trainData$classe
names(trainDataCS)[trainData$classe]
names(trainDataCS)[1]
names(trainDataCS)[1] <- "classe"
names(testDataCS)[1] <- "classe"
install.packages(c("randomForest;", "rpart;", "rpart.plot;"))
install.packages(c("randomForest", "rpart", "rpart.plot"))
library(c("randomForest", "rpart", "rpart.plot"))
suppressWarnings(library("randomForest"))
suppressWarnings(library("rpart"))
suppressWarnings(library("rpart.plot"))
controlRf <- trainControl(method = "cv", 5)
modelRf <- train(classe ~ ., data = trainDataCS, method = "rf", trControl = controlRf, ntree = 250)
predictModel <- predict(modelRf, testDataCS)
outOfSampleError <- as.numeric(confusionMatrix(testDataCS$classe, predictModel)$overall[1])
outOfSampleError
confusionMatrix(testDataCS$classe, predictModel)
outOfSampleError <- 1 - as.numeric(confusionMatrix(testDataCS$classe, predictModel)$overall[1])
outOfSampleError
confusionMatrix(testDataCS$classe, predictModel)
confusionMatrix(testDataCS$classe, predictModel)$accuracy
confusionMatrix(testDataCS$classe, predictModel)$Accuracy
confusionMatrix(testDataCS$classe, predictModel)$overall
cm <- confusionMatrix(testDataCS$classe, predictModel)
cm$overall[1]
cm$overall['Accuracy']
cm$overall['Kappa']
test <- test[,predictorCol]
result <- predict(modelRf, test)
result
install.packages(c("parallel", "doParallel"))
set.seed(1722)
inTrain <- createDataPartition(train$classe, p = 0.7)[[1]]
trainData <- train[inTrain, ]
testData <- train[-inTrain, ]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=trainData, method="rf", trControl=controlRf, ntree=250)
modelRf
result <- predict(modelRf, test)
result
library(caret)
library(ggplot2)
data(iris)
inTrain <- createDataPartition(y = iris$Species, p=0.7, list = F)
dim(inTrain)
training <- irin[inTrain,]
training <- iris[inTrain,]
testing <- irin[-inTrain,]
testing <- iris[-inTrain,]
dim(training)
qplot(Petal.Width, Sepal.Width, colors = Species, data = iris)
qplot(Petal.Width, Sepal.Width, colors = Species, data = training)
qplot(Petal.Width, Sepal.Width, colours = Species, data = training)
qplot(Petal.Width, Sepal.Width, colour =Species, data = training)
modFit <- train(Species ~ ., method = "rpart", data = training)
print(modFit$finalModel)
treeModel <- rpart(Species ~., method = "class", data = training)
prp(treeModel)
library("rpart.plot")
prp(treeModel)
?rpart
library(rattle)
install.packages("rattle")
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = testing)
?sample
library(ElemStatLearn)
install.packages("ElemStatLearn")
data(ozone)
data(ozone, package =
"ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
ss <- sample(1:dim(ozone)[1], replate = T)
ss <- sample(1:dim(ozone)[1], replace = T)
tail(ss)
tail(ozone)
dim(ozone)[1]
1:dim(ozone)[1]
ss
unique(ss)
?loess
modFitRf <- train(Species ~., data = training, method = "rf", prox = T)
modFitRf
library(pgmm)
data(olive)
dim(olive)
head(olive)
install.packages("pgmn")
library("pgmn")
library("pgmm")
install.packages("pgmm")
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive <- olive[,-1]
head(olive)
treeModel <- train(Area ~ ., data=olive, method="rpart2")
treeModel
newdata <- as.data.frame(t(colMeans(olive)))
head(nwdata)
head(newdata)
predict(treeModel, newdata)
fancyRpartPlot(newdata$finalModel)
fancyRpartPlot(treeModel$finalModel)
?randomForest
?train
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- train(y ~ ., data = vowel.train, method = "rpart2")
modelGbm <- train(y ~., data = vowel.train, method = "gbm")
modelGbm
modelGbm$results['Accuracy']
modelRf$results['Accuracy']
predictModelRf <- predict(modelRf, vowel.test)
cmModelRf <- confusionMatrix(vowel.test$y, predictModelRf)
cmModelRf$overall['Accuracy']
predictModelGbm <- predict(modelGbm, vowel.test)
cmModelGbm <- confusionMatrix(vowel.test$y, predictModelGbm)
cmModelGbm$overall['Accuracy']
cmModelRf <- confusionMatrix(predictModelRf, vowel.test$y)
cmModelRf
?confusionMatrix
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- train(y ~ ., data = vowel.train, method = "rf")
modelGbm <- train(y ~., data = vowel.train, method = "gbm")
predictModelRf <- predict(modelRf, vowel.test)
cmModelRf <- confusionMatrix(vowel.test$y, predictModelRf)
# cmModelRf$overall['Accuracy']  = 0.3766234
predictModelGbm <- predict(modelGbm, vowel.test)
cmModelGbm <- confusionMatrix(vowel.test$y, predictModelGbm)
cmModelRf$overall['Accuracy']
cmModelGbm$overall['Accuracy']
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
pred <- data.frame(predictModelRf, predictModelGbm, y=vowel.test$y, agree=predictModelRf == predictModelGbm)
head(pred)
sum(pred$agree)
sum(!pred$agree)
nrow(pred)
sum(pred$agree)/nrow(pred)
pred[agree == TRUE]['predictModelRf']
pred[pred$agree == TRUE]['predictModelRf']
pred[pred$agree == TRUE,]['predictModelRf']
accuracy <- sum(pred[pred$agree == TRUE,]['predictModelRf'] == pred[pred$agree == TRUE,]['y'])/nrow(pred)
accuracy
sum(predictModelRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
modelRf <- train(diagnosis ~ predictors, data = training, method = "rf")
set.seed(62433)
modelRf <- train(diagnosis ~ ., data = training, method = "rf")
modelGbm <- train(diagnosis ~ ., data = training, method = "gbm")
modelLda <- train(diagnosis ~ ., data = training, method = "lda")
modelLda <- train(diagnosis ~ ., data=training, method="lda")
predRf <- predict(modelRf, testing)
predGbm <- predict(modelGbm, testing)
predLda <- predict(modelLda, testing)
library(ggplot2)
qplot(predRf, predGbm, colour = diagnosis, data = testing)
qplot(predRf, predLda, colour = diagnosis, data = testing)
qplot(predGbm, predLda, colour = diagnosis, data = testing)
predDf <- data.frame(predRf, predGbm, predLda, diagnosis = testing$diagnosis)
head(predDf)
combModFit <- train(diagnosis ~ ., method = "gam", data = predDf)
combPred <- predict(combModFit, predDf)
head(combPred)
dim(dombPred)
dim(combPred)
nrow(combPred)
length(combPred)
sqrt(sum((predRf - testing$diagnosis)^2))
combModFit <- train(diagnosis ~ ., method = "rf", data = predDf)
combPred <- predict(combModFit, predDf)
head(combPred)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGbm, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLda, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(combPred, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
set.seed(62433)
modelRf <- train(diagnosis ~ ., data = training, method = "rf")
modelGbm <- train(diagnosis ~ ., data = training, method = "gbm")
modelLda <- train(diagnosis ~ ., data = training, method = "lda")
predRf <- predict(modelRf, testing)
predGbm <- predict(modelGbm, testing)
predLda <- predict(modelLda, testing)
predDf <- data.frame(predRf, predGbm, predLda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDf)
combPred <- predict(combModFit, predDf)
c1 <- confusionMatrix(predRf, testing$diagnosis)$overall[1]
c2 <- confusionMatrix(predGbm, testing$diagnosis)$overall[1]
c3 <- confusionMatrix(predLda, testing$diagnosis)$overall[1]
c4 <- confusionMatrix(combPred, testing$diagnosis)$overall[1]
print(paste(c1, c2, c3, c4))
library(gbm)
modelLda <- train(diagnosis ~ ., data = training, method = "lda")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
modelLasso <- train(CompressiveStrength ~., data = training, method = "lasso")
predLasso <- predict(modelLasso, testing)
confusionMatrix(modelLasso, testing$CompressiveStrength)
?plot.enet
plot.enet(modelLasso, testing$CompressiveStrength)
plot.enet(predLasso, testing$CompressiveStrength)
plot.enet(modelLasso$finalModel, xvar="penalty", use.color=T)
library(lubridate)  # For year() function below
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
head(tstrain)
install.packages("forecast")
?bats
?bats()
?BATS
library(forecast)
?bats
modelBats <- bats(tstrain)
predBats <- predict(modelBats, ts(testing$visitsTumblr))
head(testing)
tstest = ts(testing$visitsTumblr)
predBats <- predict(modelBats, tstest)
forecastBats <- forecast(modelBats, level = 95, h=dim(testing)[1])
names(data.frame(forecastBats))
predComb <- cbind(testing, data.frame(forecastBats))
head(predComb)
predComb$in95 <- (predComb$Lo.95 < predComb$visitsTumblr) &
(predComb$visitsTumblr < predComb$Hi.95)
head(predComb)
prop.table(table(predComb$in95))
prop.table(table(predComb$in95))[2]
install.packages("e1071")
install.packages("e1071")
library(e1071)
library('e1071')
library("e1071")
sessionInfo()
library(e1071)
install.packages("e1071")
library(e1071)
?svm
fit <- svm(CompressiveStrength ~., data=training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(325)
fit <- svm(CompressiveStrength ~., data=training)
pred <- predict(fit, testing)
confusionMatrix(pred, testing$CompressiveStrength)
library(caret)
confusionMatrix(pred, testing$CompressiveStrength)
?accuracy
library(forecast)
acc <- accuracy(pred, testing$CompressiveStrength)
acc
install.packages("manipulate")
install.packages("rchart")
install.packages("rChart")
install.packages("shiny")
library(manipulate)
manipulate(plot(1:x), x = slider(1,100))
install.packages("rCharts")
install.packages("googleVis")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages("devtools")
library(devtools)
install_github("ramnathv/rCharts@dev")
require(rCharts)
install.packages("RCurl")
install.packages("RCurl")
install.packages("Rcpp")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages("devtools")
library(devtools)
library(devtools)
install.packages("devtools")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages("Rcpp")
library(devtools)
install.packages("libcurl")
install.packages("Rcpp")
library(devtools)
install.packages("Rcpp")
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages("base64enc")
install_github("ramnathv/rCharts@dev")
install.packages("shiny")
install_github("ropensci/plotly")
install_github("rstudio/shinyapps")
require(rCharts)
haireye <- as.data.frame(HairEyeColor)
n1 <- nPlot(Freq ~ Hair, group='Eye', type='multiBarChart',
data=subset(haireye, Sex=='Male')
)
n1$save('fig/n1.html', cdn=T)
cat('<iframe src="fig/n1.html" width=100%, height=600></iframe>')
n1$save('fig/n1.html', cdn=T)
n1$save("fig/n1.html", cdn=T)
n1$save("n1.html", cdn=T)
cat('<iframe src="n1.html" width=100%, height=600></iframe>')
getwd()
setwd("C:/Users/jonovin/Desktop/Coursera Data Science/Developing Data Products")
library(slidify)
library(devtools)
install.packages("devtools")
library(devtools)
install.packages("devtools")
library(ggplot2)
library(devtools)
install_github("ramnathv/rCharts@dev")
install.packages(c("dplyr", "lubridate", "data.table", "Hmisc", "reshape2", "ggplot2", "lattice", "jsonlite", "XML", "sqldf", "knitr", "tidyr", "caret", "rpart"))
install.packages(c("rpart.plot", "randomForest", "gbm", "manipulate", "shiny", "googleVis"))
install.packages("base64enc")
install_github("ramnathv/rCharts@dev")
install_github("ropensci/plotly")
install_github("rstudio/shinyapps")
install_github('slidify', 'ramnathv'); install_github('slidifyLibraries', 'ramnathv')
install.packages("tree")
library(slidify)
library(dataset)
library(datasets)
?help
library(help = "datasets")
str(longley)
head(longley)
head(discoveries)
data("discoveries")
head(discoveries)
View(discoveries)
list.files()
getwd()
setwd("C:/Users/jonovin/Desktop/Coursera Data Science/Developing Data Products/LA Power Bill Application")
